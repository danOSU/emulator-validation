{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "filename = os.path.abspath('')+'/src'\n",
    "sys.path.insert(0,filename)\n",
    "import GPy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from configurations import load_design, transform_design\n",
    "from bayes_mcmc import *\n",
    "from emulator import *\n",
    "from calculations_load import trimmed_model_data\n",
    "from bins_and_cuts import *\n",
    "import matplotlib.patches as mpatches\n",
    "from bayes_exp import Y_exp_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following are the map parameters found by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_params = {'Pb-Pb-2760': [14.128, 0.089, 1.054, 1.064, 4.227, 1.507, 0.113, 0.223, -1.585, 0.32, 0.056, 0.11, 0.16, 0.093, -0.084, 4.666, 0.136],\n",
    "              'Au-Au-200' : [5.821, 0.089, 1.054, 1.064, 4.227, 1.507, 0.113, 0.223, -1.585, 0.32, 0.056, 0.11, 0.16, 0.093, -0.084, 4.666, 0.136]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_values=np.array(MAP_params[\"Pb-Pb-2760\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP=transform_design(map_values.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "em=Trained_Emulators['Pb-Pb-2760']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.gps[2].alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that takes Scikit lern emulator as input and return the corresponding GPy emulator.\n",
    "def convertToGPy(Scikit_emu):\n",
    "    \"\"\"Takes a scikitlearn gaussian emulator as input and return corresponding GPy gaussian emulator\"\"\"\n",
    "    dic=Scikit_emu.kernel_.get_params()\n",
    "    dim=len(dic[\"k1__k2\"].get_params()[\"length_scale\"])\n",
    "    kernel1= GPy.kern.RBF(input_dim=dim, variance=dic['k1__k1__constant_value'], lengthscale=dic[\"k1__k2\"].get_params()[\"length_scale\"],ARD=True)\n",
    "    kernal2=GPy.kern.White(input_dim=dim,variance=Scikit_emu.alpha)\n",
    "    kernel=kernel1+kernal2\n",
    "    m = GPy.models.GPRegression(Scikit_emu.X_train_,Scikit_emu.y_train_.reshape(-1,1),kernel,noise_var=dic[\"k2__noise_level\"])\n",
    "    #m.constrain_positive('') \n",
    "    #m.optimize_restarts(num_restarts = 10)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an dictionary of GPy emulators corresponding to each of the 10 PCA components of the observables\n",
    "GPy_emulators={}\n",
    "for i in range(0,10):\n",
    "    EM=em.gps[i]\n",
    "    #zz=Z.T[i].reshape(-1,1)\n",
    "    #print(zz.reshape(-1,))\n",
    "    #print(em.gps[-i].y_train_)\n",
    "    #print(zz-em.gps[i].y_train_)\n",
    "    GPy_emulators[i]=convertToGPy(Scikit_emu=EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.70035257]]), array([[0.11507379]]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPy_emulators[5].predict(Xnew=MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.70035257]), array([[0.01507379]]))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.gps[5].predict(MAP,return_cov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(0,10):\n",
    "    xp,yp=GPy_emulators[i].predict(Xnew=MAP)\n",
    "    xs,ys=em.gps[i].predict(MAP,return_cov=True)\n",
    "    data.append([i,xp.flatten(),xs.flatten(),xp.flatten()-xs.flatten(),yp.flatten(),ys.flatten(),yp.flatten()-ys.flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction of the 10 principle components for the MAP parameter values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA component</th>\n",
       "      <th>Gpy mean</th>\n",
       "      <th>GPs mean</th>\n",
       "      <th>mean difference</th>\n",
       "      <th>Gpy Cov</th>\n",
       "      <th>GPs Cov</th>\n",
       "      <th>Cov difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02842021624609714]</td>\n",
       "      <td>[-0.028420213041446374]</td>\n",
       "      <td>[-3.204650766974737e-09]</td>\n",
       "      <td>[0.11293328160662633]</td>\n",
       "      <td>[0.012933281405764774]</td>\n",
       "      <td>[0.10000000020086156]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1080975190947413]</td>\n",
       "      <td>[-0.10809752009778606]</td>\n",
       "      <td>[1.003044758363103e-09]</td>\n",
       "      <td>[0.11325435582175772]</td>\n",
       "      <td>[0.013254355592572153]</td>\n",
       "      <td>[0.10000000022918556]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.2639963713569786]</td>\n",
       "      <td>[-0.2639963724026524]</td>\n",
       "      <td>[1.0456737697950302e-09]</td>\n",
       "      <td>[0.11455936737562702]</td>\n",
       "      <td>[0.014559367085075436]</td>\n",
       "      <td>[0.10000000029055159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.33658035230470773]</td>\n",
       "      <td>[-0.3365803528460063]</td>\n",
       "      <td>[5.412985615294019e-10]</td>\n",
       "      <td>[0.11427806709265767]</td>\n",
       "      <td>[0.014278066821100666]</td>\n",
       "      <td>[0.100000000271557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.09244021557669235]</td>\n",
       "      <td>[-0.0924402158943689]</td>\n",
       "      <td>[3.176765517309832e-10]</td>\n",
       "      <td>[0.11442255270189464]</td>\n",
       "      <td>[0.014422552414210088]</td>\n",
       "      <td>[0.10000000028768455]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.7003525691208594]</td>\n",
       "      <td>[-0.7003525691555055]</td>\n",
       "      <td>[3.4646063795662485e-11]</td>\n",
       "      <td>[0.11507379243633623]</td>\n",
       "      <td>[0.015073792113875939]</td>\n",
       "      <td>[0.10000000032246029]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.2808339815640668]</td>\n",
       "      <td>[0.280833980442039]</td>\n",
       "      <td>[1.122027804001391e-09]</td>\n",
       "      <td>[0.11706744367912628]</td>\n",
       "      <td>[0.01706744328029508]</td>\n",
       "      <td>[0.1000000003988312]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.1809560011130089]</td>\n",
       "      <td>[0.1809560034658686]</td>\n",
       "      <td>[-2.3528596848620964e-09]</td>\n",
       "      <td>[0.1202581006387721]</td>\n",
       "      <td>[0.020258100100776666]</td>\n",
       "      <td>[0.10000000053799543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.6891829727880996]</td>\n",
       "      <td>[0.6891829721262539]</td>\n",
       "      <td>[6.618456893647817e-10]</td>\n",
       "      <td>[0.1976432513454313]</td>\n",
       "      <td>[0.09764325076695979]</td>\n",
       "      <td>[0.1000000005784715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.4482157121386665]</td>\n",
       "      <td>[-0.4482157184165376]</td>\n",
       "      <td>[6.277871111848299e-09]</td>\n",
       "      <td>[0.14924919968997355]</td>\n",
       "      <td>[0.04924919835091579]</td>\n",
       "      <td>[0.10000000133905776]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PCA component                Gpy mean                 GPs mean  \\\n",
       "0              0  [-0.02842021624609714]  [-0.028420213041446374]   \n",
       "1              1   [-0.1080975190947413]   [-0.10809752009778606]   \n",
       "2              2   [-0.2639963713569786]    [-0.2639963724026524]   \n",
       "3              3  [-0.33658035230470773]    [-0.3365803528460063]   \n",
       "4              4  [-0.09244021557669235]    [-0.0924402158943689]   \n",
       "5              5   [-0.7003525691208594]    [-0.7003525691555055]   \n",
       "6              6    [0.2808339815640668]      [0.280833980442039]   \n",
       "7              7    [0.1809560011130089]     [0.1809560034658686]   \n",
       "8              8    [0.6891829727880996]     [0.6891829721262539]   \n",
       "9              9   [-0.4482157121386665]    [-0.4482157184165376]   \n",
       "\n",
       "             mean difference                Gpy Cov                 GPs Cov  \\\n",
       "0   [-3.204650766974737e-09]  [0.11293328160662633]  [0.012933281405764774]   \n",
       "1    [1.003044758363103e-09]  [0.11325435582175772]  [0.013254355592572153]   \n",
       "2   [1.0456737697950302e-09]  [0.11455936737562702]  [0.014559367085075436]   \n",
       "3    [5.412985615294019e-10]  [0.11427806709265767]  [0.014278066821100666]   \n",
       "4    [3.176765517309832e-10]  [0.11442255270189464]  [0.014422552414210088]   \n",
       "5   [3.4646063795662485e-11]  [0.11507379243633623]  [0.015073792113875939]   \n",
       "6    [1.122027804001391e-09]  [0.11706744367912628]   [0.01706744328029508]   \n",
       "7  [-2.3528596848620964e-09]   [0.1202581006387721]  [0.020258100100776666]   \n",
       "8    [6.618456893647817e-10]   [0.1976432513454313]   [0.09764325076695979]   \n",
       "9    [6.277871111848299e-09]  [0.14924919968997355]   [0.04924919835091579]   \n",
       "\n",
       "          Cov difference  \n",
       "0  [0.10000000020086156]  \n",
       "1  [0.10000000022918556]  \n",
       "2  [0.10000000029055159]  \n",
       "3    [0.100000000271557]  \n",
       "4  [0.10000000028768455]  \n",
       "5  [0.10000000032246029]  \n",
       "6   [0.1000000003988312]  \n",
       "7  [0.10000000053799543]  \n",
       "8   [0.1000000005784715]  \n",
       "9  [0.10000000133905776]  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=[\"PCA component\",\"Gpy mean\",\"GPs mean\",\"mean difference\",\"Gpy Cov\",\"GPs Cov\",\"Cov difference\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I convert the GP from Scikit to Gpy there is always a difference of 0.1 in the variance. This is because to reproduce the same mean that I get from scikit learn GP I had to add a constant white noise of variance alpha to the kernal in Gpy. Otherwise the predicted means would not be the same. The mean would be different by a factor of +/- 10^(-2) if the value of alpha is not included as a constant kernal in Gpy emulator. \n",
    "\n",
    "I think this is due to the alpha paramter we use in the Scikit learn emulator training. For the trained emulators considered above alpha has been set to 0.1. Although this alpha value is added to the diagonal of the kernal while training it does not apear as part of the covariance matrix which is returend. But this alpha value is again used when the predictions are made from the trained gaussian emulator.\n",
    "\n",
    "alpha is there to ensure that the kernel matrix is positive definite, so that it can be inverted without numerical error. It should always be set to a very small positive number so it won't affect the results. But this was not clear in there earlier documentaion and now scikit learn has fixed this bug and updated there documentation. Earlier they said alpha is a parameter resembling input noise variance and it is similar to adding a white noise kernal to the covariance matrix. Now they have changed this documentation and it has no resemblance to a white noise. \n",
    "The following is the link to this bug fix.\n",
    "https://github.com/scikit-learn/scikit-learn/pull/15990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 29)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.gps[0].X_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that takes Scikit learn emulator as input and return the corresponding Pymc3 emulator.\n",
    "def convertTopymc3(Scikit_emu,i,k):\n",
    "    \"\"\"Takes a scikitlearn gaussian emulator as input and return corresponding GPy gaussian emulator\"\"\"\n",
    "    with pm.Model() as k:\n",
    "            dic=em.gps[i].kernel_.get_params()\n",
    "            Sigma2=float(dic['k1__k1__constant_value'])\n",
    "            dim=len(dic[\"k1__k2\"].get_params()[\"length_scale\"])\n",
    "            ccov=pm.gp.cov.ExpQuad(input_dim=dim, ls=dic[\"k1__k2\"].get_params()[\"length_scale\"])\n",
    "            f_cov = Sigma2 * ccov\n",
    "            cov_func_wnn=pm.gp.cov.WhiteNoise(np.sqrt(em.gps[i].alpha+dic[\"k2__noise_level\"]))\n",
    "           # cov_func_wn=np.sqrt(em.gps[0].alpha+dic[\"k2__noise_level\"])\n",
    "            m = pm.gp.Marginal(cov_func=f_cov+cov_func_wnn)\n",
    "            yt= m.marginal_likelihood(\"yt\",X=em.gps[i].X_train_,y=em.gps[i].y_train_.reshape(-1,1),noise=0)\n",
    "            mu, var = m.predict(Xnew=MAP,diag=True, pred_noise=False)\n",
    "            print(mu[0][0],var[0])\n",
    "            return mu[0][0],var[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.028420533467709338 0.11293330149269565\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "        dic=em.gps[0].kernel_.get_params()\n",
    "        Sigma2=float(dic['k1__k1__constant_value'])\n",
    "        dim=len(dic[\"k1__k2\"].get_params()[\"length_scale\"])\n",
    "        ccov=pm.gp.cov.ExpQuad(input_dim=dim, ls=dic[\"k1__k2\"].get_params()[\"length_scale\"])\n",
    "        f_cov = Sigma2 * ccov\n",
    "        cov_func_wnn=pm.gp.cov.WhiteNoise(np.sqrt(em.gps[0].alpha+dic[\"k2__noise_level\"]))\n",
    "       # cov_func_wn=np.sqrt(em.gps[0].alpha+dic[\"k2__noise_level\"])\n",
    "        m = pm.gp.Marginal(cov_func=f_cov+cov_func_wnn)\n",
    "        yt= m.marginal_likelihood(\"yt\",X=em.gps[0].X_train_,y=em.gps[0].y_train_.reshape(-1,1),noise=0)\n",
    "        mu, var = m.predict(Xnew=MAP,diag=True, pred_noise=False)\n",
    "        print(mu[0][0],var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.028420533467709338 0.11293330149269565\n",
      "-0.10809741977194727 0.11325437851029108\n",
      "-0.26399626783542635 0.11455939614026178\n",
      "-0.3365802987095955 0.11427809397632593\n",
      "-0.09244018413987454 0.11442258118283277\n",
      "-0.700352565654405 0.11507382435891778\n",
      "0.28083409268821924 0.11706748316297588\n",
      "0.18095576813667838 0.12025815389845551\n",
      "0.6891830383046265 0.1976433086122169\n",
      "-0.4482150906037686 0.14924933225854264\n"
     ]
    }
   ],
   "source": [
    "#make an dictionary of GPy emulators corresponding to each of the 10 PCA components of the observables\n",
    "pymc3_emulators_predition={}\n",
    "for i in range(0,10):\n",
    "    EM=em.gps[i]\n",
    "    pymc3_emulators_predition[i]=convertTopymc3(Scikit_emu=EM,i=i,k=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(0,10):\n",
    "    xp,yp=GPy_emulators[i].predict(Xnew=MAP)\n",
    "    xs,ys=em.gps[i].predict(MAP,return_cov=True)\n",
    "    xpm,ypm=pymc3_emulators_predition[i]\n",
    "    data.append([i,xp.flatten(),xs.flatten(),xpm,yp.flatten(),ys.flatten(),ypm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA component</th>\n",
       "      <th>Gpy mean</th>\n",
       "      <th>GPs mean</th>\n",
       "      <th>Pymc3 GP mean</th>\n",
       "      <th>Gpy Cov</th>\n",
       "      <th>GPs Cov</th>\n",
       "      <th>Pymc3 GP Cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02842021624609714]</td>\n",
       "      <td>[-0.028420213041446374]</td>\n",
       "      <td>-0.028421</td>\n",
       "      <td>[0.11293328160662619]</td>\n",
       "      <td>[0.012933281405764774]</td>\n",
       "      <td>0.112933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1080975190947413]</td>\n",
       "      <td>[-0.10809752009778606]</td>\n",
       "      <td>-0.108097</td>\n",
       "      <td>[0.11325435582176113]</td>\n",
       "      <td>[0.013254355592572153]</td>\n",
       "      <td>0.113254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.2639963713569786]</td>\n",
       "      <td>[-0.2639963724026524]</td>\n",
       "      <td>-0.263996</td>\n",
       "      <td>[0.11455936737562689]</td>\n",
       "      <td>[0.014559367085075436]</td>\n",
       "      <td>0.114559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.33658035230470773]</td>\n",
       "      <td>[-0.3365803528460063]</td>\n",
       "      <td>-0.336580</td>\n",
       "      <td>[0.11427806709265753]</td>\n",
       "      <td>[0.014278066821100666]</td>\n",
       "      <td>0.114278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.09244021557669235]</td>\n",
       "      <td>[-0.0924402158943689]</td>\n",
       "      <td>-0.092440</td>\n",
       "      <td>[0.1144225527018945]</td>\n",
       "      <td>[0.014422552414210088]</td>\n",
       "      <td>0.114423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.7003525691208594]</td>\n",
       "      <td>[-0.7003525691555055]</td>\n",
       "      <td>-0.700353</td>\n",
       "      <td>[0.11507379243633609]</td>\n",
       "      <td>[0.015073792113875939]</td>\n",
       "      <td>0.115074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.2808339815640668]</td>\n",
       "      <td>[0.280833980442039]</td>\n",
       "      <td>0.280834</td>\n",
       "      <td>[0.11706744367912614]</td>\n",
       "      <td>[0.01706744328029508]</td>\n",
       "      <td>0.117067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.1809560011130089]</td>\n",
       "      <td>[0.1809560034658686]</td>\n",
       "      <td>0.180956</td>\n",
       "      <td>[0.12025810063877196]</td>\n",
       "      <td>[0.020258100100776666]</td>\n",
       "      <td>0.120258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.6891829727880996]</td>\n",
       "      <td>[0.6891829721262539]</td>\n",
       "      <td>0.689183</td>\n",
       "      <td>[0.1976432513454312]</td>\n",
       "      <td>[0.09764325076695979]</td>\n",
       "      <td>0.197643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.4482157121386665]</td>\n",
       "      <td>[-0.4482157184165376]</td>\n",
       "      <td>-0.448215</td>\n",
       "      <td>[0.1492491996899734]</td>\n",
       "      <td>[0.04924919835091579]</td>\n",
       "      <td>0.149249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PCA component                Gpy mean                 GPs mean  \\\n",
       "0              0  [-0.02842021624609714]  [-0.028420213041446374]   \n",
       "1              1   [-0.1080975190947413]   [-0.10809752009778606]   \n",
       "2              2   [-0.2639963713569786]    [-0.2639963724026524]   \n",
       "3              3  [-0.33658035230470773]    [-0.3365803528460063]   \n",
       "4              4  [-0.09244021557669235]    [-0.0924402158943689]   \n",
       "5              5   [-0.7003525691208594]    [-0.7003525691555055]   \n",
       "6              6    [0.2808339815640668]      [0.280833980442039]   \n",
       "7              7    [0.1809560011130089]     [0.1809560034658686]   \n",
       "8              8    [0.6891829727880996]     [0.6891829721262539]   \n",
       "9              9   [-0.4482157121386665]    [-0.4482157184165376]   \n",
       "\n",
       "   Pymc3 GP mean                Gpy Cov                 GPs Cov  Pymc3 GP Cov  \n",
       "0      -0.028421  [0.11293328160662619]  [0.012933281405764774]      0.112933  \n",
       "1      -0.108097  [0.11325435582176113]  [0.013254355592572153]      0.113254  \n",
       "2      -0.263996  [0.11455936737562689]  [0.014559367085075436]      0.114559  \n",
       "3      -0.336580  [0.11427806709265753]  [0.014278066821100666]      0.114278  \n",
       "4      -0.092440   [0.1144225527018945]  [0.014422552414210088]      0.114423  \n",
       "5      -0.700353  [0.11507379243633609]  [0.015073792113875939]      0.115074  \n",
       "6       0.280834  [0.11706744367912614]   [0.01706744328029508]      0.117067  \n",
       "7       0.180956  [0.12025810063877196]  [0.020258100100776666]      0.120258  \n",
       "8       0.689183   [0.1976432513454312]   [0.09764325076695979]      0.197643  \n",
       "9      -0.448215   [0.1492491996899734]   [0.04924919835091579]      0.149249  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=[\"PCA component\",\"Gpy mean\",\"GPs mean\",\"Pymc3 GP mean\",\"Gpy Cov\",\"GPs Cov\",\"Pymc3 GP Cov\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here also to get the same mean value that is predicted by the scikit learn GP I had to add diagonal white noise with variance of the alpha value to the kernal. Other wise I do not get the same mean value. So Although the alpha value does not apear in the final prediction variance it is in the kernal and it affects the results. It is not going to be optimized during the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
